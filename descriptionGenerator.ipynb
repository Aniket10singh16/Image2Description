{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EXTREME_RED\\AppData\\Local\\Temp\\ipykernel_6692\\4289264615.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import string\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000268201_693b08cb0e.jpg#0\tA child in a pink dress is climbing up a set of stairs in an entry way .\n",
      "1000268201_693b08cb0e.jpg#1\tA girl going into a wooden building .\n",
      "1000268201_693b08cb0e.jpg#2\tA little girl climbing into a wooden playhouse .\n",
      "1000268201_693b08cb0e.jpg#3\tA little girl climbing the s\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "filename = \"Flickr8k.token.txt\"\n",
    "# load descriptions\n",
    "doc = load_doc(filename)\n",
    "print(doc[:300])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 19551 \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def read_json_file(json_file_path):\n",
    "    descriptions = {}\n",
    "    try:\n",
    "        with open(json_file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            for item in data:\n",
    "                if 'image_id' in item and 'paragraph' in item:\n",
    "                    image_id_str = str(item['image_id'])\n",
    "                    descriptions[image_id_str] = item['paragraph']\n",
    "                else:\n",
    "                    print(\"Invalid format: Missing 'image_id' or 'paragraph' key in JSON item.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Invalid JSON format in file.\")\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "    return descriptions\n",
    "\n",
    "\n",
    "json_file_path = 'paragraphs_v1.json'  # Specify the path to your JSON file\n",
    "descriptions = read_json_file(json_file_path)\n",
    "#print(\"Descriptions:\", descriptions)\n",
    "print('Loaded: %d ' % len(descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2356347', '2317429', '2414610', '2365091', '2383120']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(descriptions.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image ID: 2356347, Paragraph: A large building with bars on the windows in front of it. There is people walking in front of the building. There is a street in front of the building with many cars on it. \n",
      "Image ID: 2317429, Paragraph: A white round plate is on a table with a plastic tablecloth on it. Two foil covered food halves are on the white plate along with a serving of golden yellow french fries. Next to the white plate in a short, topless, plastic container is a white sauce. Diagonal to the white plate are the edges of several other stacked plates. There are black shadows reflected on the table.\n",
      "Image ID: 2414610, Paragraph: A woman in a blue tennis outfit stands on a green tennis court. She is swinging a blue tennis racket. There is a green tennis ball above her head. \n",
      "Image ID: 2365091, Paragraph: A large red and white train is traveling on tracks in a what looks to be a rural area. There are trees and hills in the background and the ground looks dry. The train has many large windows for the passengers to look out of. The train is mostly white with red on the front upper part of the train and red stripes and trim on the sides. The roof of the train is grey.\n",
      "Image ID: 2383120, Paragraph: A very clean and tidy a bathroom. Everything is a neat porcelain white. This bathroom is both retro and modern.\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for image_id, paragraph in descriptions.items():\n",
    "    print(f\"Image ID: {image_id}, Paragraph: {paragraph}\")\n",
    "    count += 1\n",
    "    if count == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large building with bars on the windows in front of it. There is people walking in front of the building. There is a street in front of the building with many cars on it. \n"
     ]
    }
   ],
   "source": [
    "print(descriptions['2356347'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def clean_descriptions(descriptions):\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for key, desc in descriptions.items():\n",
    "        # tokenize\n",
    "        desc = desc.split()\n",
    "        # convert to lower case\n",
    "        desc = [word.lower() for word in desc]\n",
    "        # remove punctuation from each token\n",
    "        desc = [w.translate(table) for w in desc]\n",
    "        # remove hanging 's' and 'a'\n",
    "        desc = [word for word in desc if len(word)>1]\n",
    "        # remove tokens with numbers in them\n",
    "        desc = [word for word in desc if word.isalpha()]\n",
    "        # store as string\n",
    "        descriptions[key] = ' '.join(desc)\n",
    "\n",
    "# clean descriptions\n",
    "clean_descriptions(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'woman in blue tennis outfit stands on green tennis court she is swinging blue tennis racket there is green tennis ball above her head'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions['2414610']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 13449\n"
     ]
    }
   ],
   "source": [
    "def create_vocabulary(descriptions):\n",
    "    vocabulary = set()\n",
    "    for key, desc in descriptions.items():\n",
    "        # Tokenize the paragraph into words\n",
    "        words = desc.split()\n",
    "        # Add unique words to the vocabulary set\n",
    "        vocabulary.update(words)\n",
    "    return vocabulary\n",
    "\n",
    "# Create vocabulary\n",
    "vocabulary = create_vocabulary(descriptions)\n",
    "#print(\"Vocabulary:\", vocabulary)\n",
    "print(\"Vocabulary Size:\", len(vocabulary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_descriptions_to_file(descriptions, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for key, desc in descriptions.items():\n",
    "            file.write(f\"{key} {desc}\\n\")\n",
    "\n",
    "\n",
    "file_path = 'descriptions.txt'  \n",
    "save_descriptions_to_file(descriptions, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found.\")\n",
    "        return {}\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Invalid JSON format in file.\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        return {}\n",
    "\n",
    "def save_descriptions_to_file(descriptions, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for key, desc in descriptions.items():\n",
    "            file.write(f\"{key} {desc}\\n\")\n",
    "\n",
    "# Load train_images.json file\n",
    "test_images_file_path = 'train_split.json'\n",
    "with open(test_images_file_path, 'r') as file:\n",
    "    test_images_data = json.load(file)\n",
    "\n",
    "# Convert image IDs to strings\n",
    "image_ids = [str(image_id) for image_id in test_images_data]\n",
    "\n",
    "# Filter descriptions dictionary to include only image IDs present in train_images.json\n",
    "filtered_descriptions = {key: desc for key, desc in descriptions.items() if key in image_ids}\n",
    "\n",
    "# Save filtered descriptions to a text file\n",
    "file_path = 'train_descriptions.txt'\n",
    "save_descriptions_to_file(filtered_descriptions, file_path)\n",
    "#print(\"Filtered descriptions saved to\", file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2489\n"
     ]
    }
   ],
   "source": [
    "# Load test_images.json file\n",
    "test_images_file_path = 'test_split.json'\n",
    "with open(test_images_file_path, 'r') as file:\n",
    "    test_images_data = json.load(file)\n",
    "\n",
    "# Convert image IDs to strings\n",
    "image_ids = [str(image_id) for image_id in test_images_data]\n",
    "\n",
    "# Filter descriptions dictionary to include only image IDs present in test_images.json\n",
    "filtered_descriptions = {key: desc for key, desc in descriptions.items() if key in image_ids}\n",
    "print(len(filtered_descriptions))\n",
    "# Save filtered descriptions to a text file\n",
    "file_path = 'test_descriptions.txt'\n",
    "save_descriptions_to_file(filtered_descriptions, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2487\n"
     ]
    }
   ],
   "source": [
    "# Load val_images.json file\n",
    "test_images_file_path = 'val_split.json'\n",
    "with open(test_images_file_path, 'r') as file:\n",
    "    test_images_data = json.load(file)\n",
    "\n",
    "# Convert image IDs to strings\n",
    "image_ids = [str(image_id) for image_id in test_images_data]\n",
    "\n",
    "# Filter descriptions dictionary to include only image IDs present in val_images.json\n",
    "filtered_descriptions = {key: desc for key, desc in descriptions.items() if key in image_ids}\n",
    "print(len(filtered_descriptions))\n",
    "# Save filtered descriptions to a text file\n",
    "file_path = 'val_descriptions.txt'\n",
    "save_descriptions_to_file(filtered_descriptions, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
