{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EXTREME_RED\\AppData\\Local\\Temp\\ipykernel_23732\\4086548033.py:9: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "#imports \n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torchvision\n",
    "#from pycocotools.coco import COCO\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torchvision.models import resnet152\n",
    "from torchvision.models import resnet101\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.ops import MultiScaleRoIAlign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "def get_model(num_classes):\n",
    "    # Create the Resnet-152 backbone\n",
    "    backbone = resnet152(weights=\"DEFAULT\")\n",
    "\n",
    "    # Remove the final fully connected layer (because Faster R-CNN does not need it)\n",
    "    backbone = torch.nn.Sequential(*list(backbone.children())[:-2])\n",
    "\n",
    "    # Define the number of output channels for the backbone\n",
    "    backbone.out_channels = 2048\n",
    "\n",
    "    # Create an anchor generator for the RPN\n",
    "    anchor_generator = AnchorGenerator(\n",
    "        sizes=((32, 64, 128, 256, 512),),\n",
    "        aspect_ratios=((0.5, 1.0, 2.0),)\n",
    "    )\n",
    "\n",
    "    # Define the RoI Pooler\n",
    "    roi_pooler = MultiScaleRoIAlign(\n",
    "        featmap_names=[\"0\"],\n",
    "        output_size=7,\n",
    "        sampling_ratio=2\n",
    "    )\n",
    "\n",
    "    for param in backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Create Faster R-CNN with the Resnet-152 backbone\n",
    "    model = FasterRCNN(\n",
    "        backbone,\n",
    "        num_classes=num_classes,  # Adjust this to your custom dataset's number of classes\n",
    "        rpn_anchor_generator=anchor_generator,\n",
    "        box_roi_pool=roi_pooler\n",
    "    )\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_path,transform):\n",
    "        # Load annotations from JSON\n",
    "        with open(data_path) as f:\n",
    "            data = json.load(f)\n",
    "        self.images = data['images']\n",
    "        self.annotations = data['annotations']\n",
    "        self.categories = {cat['id']: cat['name'] for cat in data['categories']}\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image and annotations\n",
    "        img_info = self.images[idx]\n",
    "        mg_location = os.path.join('D:\\\\WORK\\\\M.SC\\\\MSC_Project\\\\GitHub\\\\Dataset\\\\VG\\\\VG_100K',img_info['file_name'])\n",
    "        image = Image.open(mg_location).convert(\"RGB\")\n",
    "\n",
    "        #apply the transfromation to the image\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": torch.empty((0, 4), dtype=torch.float32),  # Empty tensor with shape [0, 4]\n",
    "            \"labels\": torch.empty((0,), dtype=torch.int64),  # Empty tensor with shape [0]\n",
    "            \"image_id\": torch.tensor([img_info['id']]),\n",
    "            \"area\": torch.empty((0,), dtype=torch.float32),  # Empty tensor with shape [0]\n",
    "            \"iscrowd\": torch.empty((0,), dtype=torch.int64)  # Empty tensor with shape [0]\n",
    "        }\n",
    "\n",
    "        for ann in self.annotations:\n",
    "            if ann['image_id'] == img_info['id']:\n",
    "                # Convert bbox values to integers\n",
    "                bbox = [int(round(val)) for val in ann[\"bbox\"]]\n",
    "                # Transform (x, y, w, h) to (x1, y1, x2, y2)\n",
    "                x, y, w, h = bbox\n",
    "                x1, y1 = x, y\n",
    "                x2, y2 = x + w, y + h\n",
    "                target[\"boxes\"] = torch.vstack((target[\"boxes\"], torch.tensor([x1, y1, x2, y2])))\n",
    "                target[\"labels\"] = torch.hstack((target[\"labels\"], torch.tensor(ann[\"category_id\"])))\n",
    "                target[\"area\"] = torch.hstack((target[\"area\"], torch.tensor(ann[\"area\"])))\n",
    "                target[\"iscrowd\"] = torch.hstack((target[\"iscrowd\"], torch.tensor(ann[\"iscrowd\"])))\n",
    "\n",
    "        # Convert lists to tensors\n",
    "        for key in target:\n",
    "            if key != \"image_id\":\n",
    "                target[key] = torch.tensor(target[key])\n",
    "\n",
    "        return image, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle varying sizes of the targets within the batch.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    targets = []\n",
    "    \n",
    "    for item in batch:\n",
    "        images.append(item[0])\n",
    "        targets.append(item[1])\n",
    "    \n",
    "    return images, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.Resize((800, 800)), T.ToTensor(), T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])\n",
    "dataset = CustomDataset('D:\\\\WORK\\\\M.SC\\\\MSC_Project\\\\GitHub\\\\Image2Description\\\\instances_vg3k_cocoaligned_train.json',transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CocoDetection\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#transform = T.Compose([T.Resize((800, 800)), T.ToTensor(), T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])\n",
    "# Load the dataset\n",
    "#dataset = CocoDetection(root='D:\\\\WORK\\\\M.SC\\\\MSC_Project\\\\GitHub\\\\Dataset\\\\VG\\\\VG_100K', annFile='D:\\\\WORK\\\\M.SC\\\\MSC_Project\\\\GitHub\\\\Image2Description\\\\instances_vg3k_cocoaligned_train.json', transform=transform)\n",
    "#dataset_test = CocoDetection(root='D:\\\\WORK\\\\M.SC\\\\MSC_Project\\\\GitHub\\\\Dataset\\\\VG\\\\VG_100K', annFile='D:\\\\WORK\\\\M.SC\\\\MSC_Project\\\\GitHub\\\\Image2Description\\\\instances_vg3k_cocoaligned_val.json', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EXTREME_RED\\AppData\\Local\\Temp\\ipykernel_23732\\2569167509.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target[key] = torch.tensor(target[key])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m targets \u001b[38;5;241m=\u001b[39m [{k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m targets]\n\u001b[0;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 23\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(loss \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m loss_dict\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m     25\u001b[0m losses\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\EXTREME_RED\\anaconda3\\envs\\Final_Project_V2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\EXTREME_RED\\anaconda3\\envs\\Final_Project_V2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\EXTREME_RED\\anaconda3\\envs\\Final_Project_V2\\Lib\\site-packages\\torchvision\\models\\detection\\generalized_rcnn.py:105\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[1;34m(self, images, targets)\u001b[0m\n\u001b[0;32m    103\u001b[0m     features \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, features)])\n\u001b[0;32m    104\u001b[0m proposals, proposal_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrpn(images, features, targets)\n\u001b[1;32m--> 105\u001b[0m detections, detector_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroi_heads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproposals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m detections \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mpostprocess(detections, images\u001b[38;5;241m.\u001b[39mimage_sizes, original_image_sizes)  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[0;32m    108\u001b[0m losses \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\EXTREME_RED\\anaconda3\\envs\\Final_Project_V2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\EXTREME_RED\\anaconda3\\envs\\Final_Project_V2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\EXTREME_RED\\anaconda3\\envs\\Final_Project_V2\\Lib\\site-packages\\torchvision\\models\\detection\\roi_heads.py:772\u001b[0m, in \u001b[0;36mRoIHeads.forward\u001b[1;34m(self, features, proposals, image_shapes, targets)\u001b[0m\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m regression_targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression_targets cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 772\u001b[0m     loss_classifier, loss_box_reg \u001b[38;5;241m=\u001b[39m \u001b[43mfastrcnn_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox_regression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregression_targets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    773\u001b[0m     losses \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss_classifier, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_box_reg\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss_box_reg}\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\EXTREME_RED\\anaconda3\\envs\\Final_Project_V2\\Lib\\site-packages\\torchvision\\models\\detection\\roi_heads.py:36\u001b[0m, in \u001b[0;36mfastrcnn_loss\u001b[1;34m(class_logits, box_regression, labels, regression_targets)\u001b[0m\n\u001b[0;32m     31\u001b[0m classification_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(class_logits, labels)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# get indices that correspond to the regression targets for\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# the corresponding ground truth labels, to be used with\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# advanced indexing\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m sampled_pos_inds_subset \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     37\u001b[0m labels_pos \u001b[38;5;241m=\u001b[39m labels[sampled_pos_inds_subset]\n\u001b[0;32m     38\u001b[0m N, num_classes \u001b[38;5;241m=\u001b[39m class_logits\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define data loaders\n",
    "data_loader = DataLoader(dataset, batch_size=8, shuffle=True,collate_fn=custom_collate_fn)\n",
    "#data_loader_test = DataLoader(dataset_test, batch_size=8, shuffle=False)\n",
    "model=get_model(3000)\n",
    "model = model.to(device)  # Move the model to GPU\n",
    "\n",
    "# Set up optimizer and learning rate scheduler\n",
    "# Define your optimizer and scheduler\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train your model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, targets in data_loader:\n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        optimizer.zero_grad()\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Update learning rate\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # Print loss\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {losses.item()}\")\n",
    "\n",
    "# Save your trained model\n",
    "torch.save(model.state_dict(), 'trained_model.pth')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "results = []\n",
    "\n",
    "'''for images, targets in data_loader_test:\n",
    "    images = list(image.to(device) for image in images)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "    outputs = model(images)\n",
    "    results.extend(outputs)'''\n",
    "\n",
    "# Process results as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FasterRCNN(\n",
      "  (transform): GeneralizedRCNNTransform(\n",
      "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
      "  )\n",
      "  (backbone): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (6): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (7): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (6): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (7): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (8): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (9): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (10): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (11): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (12): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (13): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (14): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (15): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (16): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (17): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (18): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (19): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (20): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (21): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (22): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (23): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (24): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (25): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (26): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (27): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (28): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (29): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (30): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (31): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (32): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (33): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (34): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (35): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (rpn): RegionProposalNetwork(\n",
      "    (anchor_generator): AnchorGenerator()\n",
      "    (head): RPNHead(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cls_logits): Conv2d(2048, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bbox_pred): Conv2d(2048, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): RoIHeads(\n",
      "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0'], output_size=(7, 7), sampling_ratio=2)\n",
      "    (box_head): TwoMLPHead(\n",
      "      (fc6): Linear(in_features=100352, out_features=1024, bias=True)\n",
      "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNPredictor(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3000, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12000, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total parameters: 215234339\n",
      "backbone.0.weight torch.Size([64, 3, 7, 7])\n",
      "backbone.1.weight torch.Size([64])\n",
      "backbone.1.bias torch.Size([64])\n",
      "backbone.4.0.conv1.weight torch.Size([64, 64, 1, 1])\n",
      "backbone.4.0.bn1.weight torch.Size([64])\n",
      "backbone.4.0.bn1.bias torch.Size([64])\n",
      "backbone.4.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "backbone.4.0.bn2.weight torch.Size([64])\n",
      "backbone.4.0.bn2.bias torch.Size([64])\n",
      "backbone.4.0.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "backbone.4.0.bn3.weight torch.Size([256])\n",
      "backbone.4.0.bn3.bias torch.Size([256])\n",
      "backbone.4.0.downsample.0.weight torch.Size([256, 64, 1, 1])\n",
      "backbone.4.0.downsample.1.weight torch.Size([256])\n",
      "backbone.4.0.downsample.1.bias torch.Size([256])\n",
      "backbone.4.1.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "backbone.4.1.bn1.weight torch.Size([64])\n",
      "backbone.4.1.bn1.bias torch.Size([64])\n",
      "backbone.4.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "backbone.4.1.bn2.weight torch.Size([64])\n",
      "backbone.4.1.bn2.bias torch.Size([64])\n",
      "backbone.4.1.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "backbone.4.1.bn3.weight torch.Size([256])\n",
      "backbone.4.1.bn3.bias torch.Size([256])\n",
      "backbone.4.2.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "backbone.4.2.bn1.weight torch.Size([64])\n",
      "backbone.4.2.bn1.bias torch.Size([64])\n",
      "backbone.4.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "backbone.4.2.bn2.weight torch.Size([64])\n",
      "backbone.4.2.bn2.bias torch.Size([64])\n",
      "backbone.4.2.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "backbone.4.2.bn3.weight torch.Size([256])\n",
      "backbone.4.2.bn3.bias torch.Size([256])\n",
      "backbone.5.0.conv1.weight torch.Size([128, 256, 1, 1])\n",
      "backbone.5.0.bn1.weight torch.Size([128])\n",
      "backbone.5.0.bn1.bias torch.Size([128])\n",
      "backbone.5.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "backbone.5.0.bn2.weight torch.Size([128])\n",
      "backbone.5.0.bn2.bias torch.Size([128])\n",
      "backbone.5.0.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "backbone.5.0.bn3.weight torch.Size([512])\n",
      "backbone.5.0.bn3.bias torch.Size([512])\n",
      "backbone.5.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
      "backbone.5.0.downsample.1.weight torch.Size([512])\n",
      "backbone.5.0.downsample.1.bias torch.Size([512])\n",
      "backbone.5.1.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "backbone.5.1.bn1.weight torch.Size([128])\n",
      "backbone.5.1.bn1.bias torch.Size([128])\n",
      "backbone.5.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "backbone.5.1.bn2.weight torch.Size([128])\n",
      "backbone.5.1.bn2.bias torch.Size([128])\n",
      "backbone.5.1.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "backbone.5.1.bn3.weight torch.Size([512])\n",
      "backbone.5.1.bn3.bias torch.Size([512])\n",
      "backbone.5.2.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "backbone.5.2.bn1.weight torch.Size([128])\n",
      "backbone.5.2.bn1.bias torch.Size([128])\n",
      "backbone.5.2.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "backbone.5.2.bn2.weight torch.Size([128])\n",
      "backbone.5.2.bn2.bias torch.Size([128])\n",
      "backbone.5.2.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "backbone.5.2.bn3.weight torch.Size([512])\n",
      "backbone.5.2.bn3.bias torch.Size([512])\n",
      "backbone.5.3.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "backbone.5.3.bn1.weight torch.Size([128])\n",
      "backbone.5.3.bn1.bias torch.Size([128])\n",
      "backbone.5.3.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "backbone.5.3.bn2.weight torch.Size([128])\n",
      "backbone.5.3.bn2.bias torch.Size([128])\n",
      "backbone.5.3.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "backbone.5.3.bn3.weight torch.Size([512])\n",
      "backbone.5.3.bn3.bias torch.Size([512])\n",
      "backbone.5.4.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "backbone.5.4.bn1.weight torch.Size([128])\n",
      "backbone.5.4.bn1.bias torch.Size([128])\n",
      "backbone.5.4.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "backbone.5.4.bn2.weight torch.Size([128])\n",
      "backbone.5.4.bn2.bias torch.Size([128])\n",
      "backbone.5.4.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "backbone.5.4.bn3.weight torch.Size([512])\n",
      "backbone.5.4.bn3.bias torch.Size([512])\n",
      "backbone.5.5.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "backbone.5.5.bn1.weight torch.Size([128])\n",
      "backbone.5.5.bn1.bias torch.Size([128])\n",
      "backbone.5.5.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "backbone.5.5.bn2.weight torch.Size([128])\n",
      "backbone.5.5.bn2.bias torch.Size([128])\n",
      "backbone.5.5.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "backbone.5.5.bn3.weight torch.Size([512])\n",
      "backbone.5.5.bn3.bias torch.Size([512])\n",
      "backbone.5.6.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "backbone.5.6.bn1.weight torch.Size([128])\n",
      "backbone.5.6.bn1.bias torch.Size([128])\n",
      "backbone.5.6.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "backbone.5.6.bn2.weight torch.Size([128])\n",
      "backbone.5.6.bn2.bias torch.Size([128])\n",
      "backbone.5.6.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "backbone.5.6.bn3.weight torch.Size([512])\n",
      "backbone.5.6.bn3.bias torch.Size([512])\n",
      "backbone.5.7.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "backbone.5.7.bn1.weight torch.Size([128])\n",
      "backbone.5.7.bn1.bias torch.Size([128])\n",
      "backbone.5.7.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "backbone.5.7.bn2.weight torch.Size([128])\n",
      "backbone.5.7.bn2.bias torch.Size([128])\n",
      "backbone.5.7.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "backbone.5.7.bn3.weight torch.Size([512])\n",
      "backbone.5.7.bn3.bias torch.Size([512])\n",
      "backbone.6.0.conv1.weight torch.Size([256, 512, 1, 1])\n",
      "backbone.6.0.bn1.weight torch.Size([256])\n",
      "backbone.6.0.bn1.bias torch.Size([256])\n",
      "backbone.6.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.0.bn2.weight torch.Size([256])\n",
      "backbone.6.0.bn2.bias torch.Size([256])\n",
      "backbone.6.0.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.0.bn3.weight torch.Size([1024])\n",
      "backbone.6.0.bn3.bias torch.Size([1024])\n",
      "backbone.6.0.downsample.0.weight torch.Size([1024, 512, 1, 1])\n",
      "backbone.6.0.downsample.1.weight torch.Size([1024])\n",
      "backbone.6.0.downsample.1.bias torch.Size([1024])\n",
      "backbone.6.1.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.1.bn1.weight torch.Size([256])\n",
      "backbone.6.1.bn1.bias torch.Size([256])\n",
      "backbone.6.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.1.bn2.weight torch.Size([256])\n",
      "backbone.6.1.bn2.bias torch.Size([256])\n",
      "backbone.6.1.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.1.bn3.weight torch.Size([1024])\n",
      "backbone.6.1.bn3.bias torch.Size([1024])\n",
      "backbone.6.2.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.2.bn1.weight torch.Size([256])\n",
      "backbone.6.2.bn1.bias torch.Size([256])\n",
      "backbone.6.2.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.2.bn2.weight torch.Size([256])\n",
      "backbone.6.2.bn2.bias torch.Size([256])\n",
      "backbone.6.2.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.2.bn3.weight torch.Size([1024])\n",
      "backbone.6.2.bn3.bias torch.Size([1024])\n",
      "backbone.6.3.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.3.bn1.weight torch.Size([256])\n",
      "backbone.6.3.bn1.bias torch.Size([256])\n",
      "backbone.6.3.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.3.bn2.weight torch.Size([256])\n",
      "backbone.6.3.bn2.bias torch.Size([256])\n",
      "backbone.6.3.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.3.bn3.weight torch.Size([1024])\n",
      "backbone.6.3.bn3.bias torch.Size([1024])\n",
      "backbone.6.4.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.4.bn1.weight torch.Size([256])\n",
      "backbone.6.4.bn1.bias torch.Size([256])\n",
      "backbone.6.4.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.4.bn2.weight torch.Size([256])\n",
      "backbone.6.4.bn2.bias torch.Size([256])\n",
      "backbone.6.4.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.4.bn3.weight torch.Size([1024])\n",
      "backbone.6.4.bn3.bias torch.Size([1024])\n",
      "backbone.6.5.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.5.bn1.weight torch.Size([256])\n",
      "backbone.6.5.bn1.bias torch.Size([256])\n",
      "backbone.6.5.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.5.bn2.weight torch.Size([256])\n",
      "backbone.6.5.bn2.bias torch.Size([256])\n",
      "backbone.6.5.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.5.bn3.weight torch.Size([1024])\n",
      "backbone.6.5.bn3.bias torch.Size([1024])\n",
      "backbone.6.6.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.6.bn1.weight torch.Size([256])\n",
      "backbone.6.6.bn1.bias torch.Size([256])\n",
      "backbone.6.6.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.6.bn2.weight torch.Size([256])\n",
      "backbone.6.6.bn2.bias torch.Size([256])\n",
      "backbone.6.6.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.6.bn3.weight torch.Size([1024])\n",
      "backbone.6.6.bn3.bias torch.Size([1024])\n",
      "backbone.6.7.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.7.bn1.weight torch.Size([256])\n",
      "backbone.6.7.bn1.bias torch.Size([256])\n",
      "backbone.6.7.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.7.bn2.weight torch.Size([256])\n",
      "backbone.6.7.bn2.bias torch.Size([256])\n",
      "backbone.6.7.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.7.bn3.weight torch.Size([1024])\n",
      "backbone.6.7.bn3.bias torch.Size([1024])\n",
      "backbone.6.8.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.8.bn1.weight torch.Size([256])\n",
      "backbone.6.8.bn1.bias torch.Size([256])\n",
      "backbone.6.8.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.8.bn2.weight torch.Size([256])\n",
      "backbone.6.8.bn2.bias torch.Size([256])\n",
      "backbone.6.8.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.8.bn3.weight torch.Size([1024])\n",
      "backbone.6.8.bn3.bias torch.Size([1024])\n",
      "backbone.6.9.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.9.bn1.weight torch.Size([256])\n",
      "backbone.6.9.bn1.bias torch.Size([256])\n",
      "backbone.6.9.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.9.bn2.weight torch.Size([256])\n",
      "backbone.6.9.bn2.bias torch.Size([256])\n",
      "backbone.6.9.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.9.bn3.weight torch.Size([1024])\n",
      "backbone.6.9.bn3.bias torch.Size([1024])\n",
      "backbone.6.10.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.10.bn1.weight torch.Size([256])\n",
      "backbone.6.10.bn1.bias torch.Size([256])\n",
      "backbone.6.10.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.10.bn2.weight torch.Size([256])\n",
      "backbone.6.10.bn2.bias torch.Size([256])\n",
      "backbone.6.10.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.10.bn3.weight torch.Size([1024])\n",
      "backbone.6.10.bn3.bias torch.Size([1024])\n",
      "backbone.6.11.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.11.bn1.weight torch.Size([256])\n",
      "backbone.6.11.bn1.bias torch.Size([256])\n",
      "backbone.6.11.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.11.bn2.weight torch.Size([256])\n",
      "backbone.6.11.bn2.bias torch.Size([256])\n",
      "backbone.6.11.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.11.bn3.weight torch.Size([1024])\n",
      "backbone.6.11.bn3.bias torch.Size([1024])\n",
      "backbone.6.12.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.12.bn1.weight torch.Size([256])\n",
      "backbone.6.12.bn1.bias torch.Size([256])\n",
      "backbone.6.12.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.12.bn2.weight torch.Size([256])\n",
      "backbone.6.12.bn2.bias torch.Size([256])\n",
      "backbone.6.12.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.12.bn3.weight torch.Size([1024])\n",
      "backbone.6.12.bn3.bias torch.Size([1024])\n",
      "backbone.6.13.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.13.bn1.weight torch.Size([256])\n",
      "backbone.6.13.bn1.bias torch.Size([256])\n",
      "backbone.6.13.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.13.bn2.weight torch.Size([256])\n",
      "backbone.6.13.bn2.bias torch.Size([256])\n",
      "backbone.6.13.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.13.bn3.weight torch.Size([1024])\n",
      "backbone.6.13.bn3.bias torch.Size([1024])\n",
      "backbone.6.14.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.14.bn1.weight torch.Size([256])\n",
      "backbone.6.14.bn1.bias torch.Size([256])\n",
      "backbone.6.14.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.14.bn2.weight torch.Size([256])\n",
      "backbone.6.14.bn2.bias torch.Size([256])\n",
      "backbone.6.14.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.14.bn3.weight torch.Size([1024])\n",
      "backbone.6.14.bn3.bias torch.Size([1024])\n",
      "backbone.6.15.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.15.bn1.weight torch.Size([256])\n",
      "backbone.6.15.bn1.bias torch.Size([256])\n",
      "backbone.6.15.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.15.bn2.weight torch.Size([256])\n",
      "backbone.6.15.bn2.bias torch.Size([256])\n",
      "backbone.6.15.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.15.bn3.weight torch.Size([1024])\n",
      "backbone.6.15.bn3.bias torch.Size([1024])\n",
      "backbone.6.16.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.16.bn1.weight torch.Size([256])\n",
      "backbone.6.16.bn1.bias torch.Size([256])\n",
      "backbone.6.16.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.16.bn2.weight torch.Size([256])\n",
      "backbone.6.16.bn2.bias torch.Size([256])\n",
      "backbone.6.16.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.16.bn3.weight torch.Size([1024])\n",
      "backbone.6.16.bn3.bias torch.Size([1024])\n",
      "backbone.6.17.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.17.bn1.weight torch.Size([256])\n",
      "backbone.6.17.bn1.bias torch.Size([256])\n",
      "backbone.6.17.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.17.bn2.weight torch.Size([256])\n",
      "backbone.6.17.bn2.bias torch.Size([256])\n",
      "backbone.6.17.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.17.bn3.weight torch.Size([1024])\n",
      "backbone.6.17.bn3.bias torch.Size([1024])\n",
      "backbone.6.18.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.18.bn1.weight torch.Size([256])\n",
      "backbone.6.18.bn1.bias torch.Size([256])\n",
      "backbone.6.18.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.18.bn2.weight torch.Size([256])\n",
      "backbone.6.18.bn2.bias torch.Size([256])\n",
      "backbone.6.18.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.18.bn3.weight torch.Size([1024])\n",
      "backbone.6.18.bn3.bias torch.Size([1024])\n",
      "backbone.6.19.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.19.bn1.weight torch.Size([256])\n",
      "backbone.6.19.bn1.bias torch.Size([256])\n",
      "backbone.6.19.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.19.bn2.weight torch.Size([256])\n",
      "backbone.6.19.bn2.bias torch.Size([256])\n",
      "backbone.6.19.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.19.bn3.weight torch.Size([1024])\n",
      "backbone.6.19.bn3.bias torch.Size([1024])\n",
      "backbone.6.20.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.20.bn1.weight torch.Size([256])\n",
      "backbone.6.20.bn1.bias torch.Size([256])\n",
      "backbone.6.20.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.20.bn2.weight torch.Size([256])\n",
      "backbone.6.20.bn2.bias torch.Size([256])\n",
      "backbone.6.20.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.20.bn3.weight torch.Size([1024])\n",
      "backbone.6.20.bn3.bias torch.Size([1024])\n",
      "backbone.6.21.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.21.bn1.weight torch.Size([256])\n",
      "backbone.6.21.bn1.bias torch.Size([256])\n",
      "backbone.6.21.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.21.bn2.weight torch.Size([256])\n",
      "backbone.6.21.bn2.bias torch.Size([256])\n",
      "backbone.6.21.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.21.bn3.weight torch.Size([1024])\n",
      "backbone.6.21.bn3.bias torch.Size([1024])\n",
      "backbone.6.22.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.22.bn1.weight torch.Size([256])\n",
      "backbone.6.22.bn1.bias torch.Size([256])\n",
      "backbone.6.22.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.22.bn2.weight torch.Size([256])\n",
      "backbone.6.22.bn2.bias torch.Size([256])\n",
      "backbone.6.22.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.22.bn3.weight torch.Size([1024])\n",
      "backbone.6.22.bn3.bias torch.Size([1024])\n",
      "backbone.6.23.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.23.bn1.weight torch.Size([256])\n",
      "backbone.6.23.bn1.bias torch.Size([256])\n",
      "backbone.6.23.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.23.bn2.weight torch.Size([256])\n",
      "backbone.6.23.bn2.bias torch.Size([256])\n",
      "backbone.6.23.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.23.bn3.weight torch.Size([1024])\n",
      "backbone.6.23.bn3.bias torch.Size([1024])\n",
      "backbone.6.24.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.24.bn1.weight torch.Size([256])\n",
      "backbone.6.24.bn1.bias torch.Size([256])\n",
      "backbone.6.24.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.24.bn2.weight torch.Size([256])\n",
      "backbone.6.24.bn2.bias torch.Size([256])\n",
      "backbone.6.24.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.24.bn3.weight torch.Size([1024])\n",
      "backbone.6.24.bn3.bias torch.Size([1024])\n",
      "backbone.6.25.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.25.bn1.weight torch.Size([256])\n",
      "backbone.6.25.bn1.bias torch.Size([256])\n",
      "backbone.6.25.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.25.bn2.weight torch.Size([256])\n",
      "backbone.6.25.bn2.bias torch.Size([256])\n",
      "backbone.6.25.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.25.bn3.weight torch.Size([1024])\n",
      "backbone.6.25.bn3.bias torch.Size([1024])\n",
      "backbone.6.26.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.26.bn1.weight torch.Size([256])\n",
      "backbone.6.26.bn1.bias torch.Size([256])\n",
      "backbone.6.26.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.26.bn2.weight torch.Size([256])\n",
      "backbone.6.26.bn2.bias torch.Size([256])\n",
      "backbone.6.26.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.26.bn3.weight torch.Size([1024])\n",
      "backbone.6.26.bn3.bias torch.Size([1024])\n",
      "backbone.6.27.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.27.bn1.weight torch.Size([256])\n",
      "backbone.6.27.bn1.bias torch.Size([256])\n",
      "backbone.6.27.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.27.bn2.weight torch.Size([256])\n",
      "backbone.6.27.bn2.bias torch.Size([256])\n",
      "backbone.6.27.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.27.bn3.weight torch.Size([1024])\n",
      "backbone.6.27.bn3.bias torch.Size([1024])\n",
      "backbone.6.28.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.28.bn1.weight torch.Size([256])\n",
      "backbone.6.28.bn1.bias torch.Size([256])\n",
      "backbone.6.28.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.28.bn2.weight torch.Size([256])\n",
      "backbone.6.28.bn2.bias torch.Size([256])\n",
      "backbone.6.28.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.28.bn3.weight torch.Size([1024])\n",
      "backbone.6.28.bn3.bias torch.Size([1024])\n",
      "backbone.6.29.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.29.bn1.weight torch.Size([256])\n",
      "backbone.6.29.bn1.bias torch.Size([256])\n",
      "backbone.6.29.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.29.bn2.weight torch.Size([256])\n",
      "backbone.6.29.bn2.bias torch.Size([256])\n",
      "backbone.6.29.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.29.bn3.weight torch.Size([1024])\n",
      "backbone.6.29.bn3.bias torch.Size([1024])\n",
      "backbone.6.30.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.30.bn1.weight torch.Size([256])\n",
      "backbone.6.30.bn1.bias torch.Size([256])\n",
      "backbone.6.30.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.30.bn2.weight torch.Size([256])\n",
      "backbone.6.30.bn2.bias torch.Size([256])\n",
      "backbone.6.30.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.30.bn3.weight torch.Size([1024])\n",
      "backbone.6.30.bn3.bias torch.Size([1024])\n",
      "backbone.6.31.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.31.bn1.weight torch.Size([256])\n",
      "backbone.6.31.bn1.bias torch.Size([256])\n",
      "backbone.6.31.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.31.bn2.weight torch.Size([256])\n",
      "backbone.6.31.bn2.bias torch.Size([256])\n",
      "backbone.6.31.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.31.bn3.weight torch.Size([1024])\n",
      "backbone.6.31.bn3.bias torch.Size([1024])\n",
      "backbone.6.32.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.32.bn1.weight torch.Size([256])\n",
      "backbone.6.32.bn1.bias torch.Size([256])\n",
      "backbone.6.32.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.32.bn2.weight torch.Size([256])\n",
      "backbone.6.32.bn2.bias torch.Size([256])\n",
      "backbone.6.32.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.32.bn3.weight torch.Size([1024])\n",
      "backbone.6.32.bn3.bias torch.Size([1024])\n",
      "backbone.6.33.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.33.bn1.weight torch.Size([256])\n",
      "backbone.6.33.bn1.bias torch.Size([256])\n",
      "backbone.6.33.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.33.bn2.weight torch.Size([256])\n",
      "backbone.6.33.bn2.bias torch.Size([256])\n",
      "backbone.6.33.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.33.bn3.weight torch.Size([1024])\n",
      "backbone.6.33.bn3.bias torch.Size([1024])\n",
      "backbone.6.34.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.34.bn1.weight torch.Size([256])\n",
      "backbone.6.34.bn1.bias torch.Size([256])\n",
      "backbone.6.34.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.34.bn2.weight torch.Size([256])\n",
      "backbone.6.34.bn2.bias torch.Size([256])\n",
      "backbone.6.34.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.34.bn3.weight torch.Size([1024])\n",
      "backbone.6.34.bn3.bias torch.Size([1024])\n",
      "backbone.6.35.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.6.35.bn1.weight torch.Size([256])\n",
      "backbone.6.35.bn1.bias torch.Size([256])\n",
      "backbone.6.35.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.6.35.bn2.weight torch.Size([256])\n",
      "backbone.6.35.bn2.bias torch.Size([256])\n",
      "backbone.6.35.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.6.35.bn3.weight torch.Size([1024])\n",
      "backbone.6.35.bn3.bias torch.Size([1024])\n",
      "backbone.7.0.conv1.weight torch.Size([512, 1024, 1, 1])\n",
      "backbone.7.0.bn1.weight torch.Size([512])\n",
      "backbone.7.0.bn1.bias torch.Size([512])\n",
      "backbone.7.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "backbone.7.0.bn2.weight torch.Size([512])\n",
      "backbone.7.0.bn2.bias torch.Size([512])\n",
      "backbone.7.0.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "backbone.7.0.bn3.weight torch.Size([2048])\n",
      "backbone.7.0.bn3.bias torch.Size([2048])\n",
      "backbone.7.0.downsample.0.weight torch.Size([2048, 1024, 1, 1])\n",
      "backbone.7.0.downsample.1.weight torch.Size([2048])\n",
      "backbone.7.0.downsample.1.bias torch.Size([2048])\n",
      "backbone.7.1.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "backbone.7.1.bn1.weight torch.Size([512])\n",
      "backbone.7.1.bn1.bias torch.Size([512])\n",
      "backbone.7.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "backbone.7.1.bn2.weight torch.Size([512])\n",
      "backbone.7.1.bn2.bias torch.Size([512])\n",
      "backbone.7.1.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "backbone.7.1.bn3.weight torch.Size([2048])\n",
      "backbone.7.1.bn3.bias torch.Size([2048])\n",
      "backbone.7.2.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "backbone.7.2.bn1.weight torch.Size([512])\n",
      "backbone.7.2.bn1.bias torch.Size([512])\n",
      "backbone.7.2.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "backbone.7.2.bn2.weight torch.Size([512])\n",
      "backbone.7.2.bn2.bias torch.Size([512])\n",
      "backbone.7.2.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "backbone.7.2.bn3.weight torch.Size([2048])\n",
      "backbone.7.2.bn3.bias torch.Size([2048])\n",
      "rpn.head.conv.0.0.weight torch.Size([2048, 2048, 3, 3])\n",
      "rpn.head.conv.0.0.bias torch.Size([2048])\n",
      "rpn.head.cls_logits.weight torch.Size([15, 2048, 1, 1])\n",
      "rpn.head.cls_logits.bias torch.Size([15])\n",
      "rpn.head.bbox_pred.weight torch.Size([60, 2048, 1, 1])\n",
      "rpn.head.bbox_pred.bias torch.Size([60])\n",
      "roi_heads.box_head.fc6.weight torch.Size([1024, 100352])\n",
      "roi_heads.box_head.fc6.bias torch.Size([1024])\n",
      "roi_heads.box_head.fc7.weight torch.Size([1024, 1024])\n",
      "roi_heads.box_head.fc7.bias torch.Size([1024])\n",
      "roi_heads.box_predictor.cls_score.weight torch.Size([3000, 1024])\n",
      "roi_heads.box_predictor.cls_score.bias torch.Size([3000])\n",
      "roi_heads.box_predictor.bbox_pred.weight torch.Size([12000, 1024])\n",
      "roi_heads.box_predictor.bbox_pred.bias torch.Size([12000])\n"
     ]
    }
   ],
   "source": [
    "# Move model to GPU\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total parameters:\", total_params)\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Final_Project_V2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
