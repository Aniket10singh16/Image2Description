{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2 \n",
    "import pandas \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.image as mpimg\n",
    "import networkx as nx\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath=r\"D:\\\\Paper\\\\Mimic Human Level Intelligence in Image Descriptioning\\\\Flicker8k_Dataset\\\\109202801_c6381eef15.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Object Detection using YOLOv8\n",
    "def detect_objects(imagePath):\n",
    "    image=cv2.imread(imagePath)\n",
    "    image=cv2.resize(image,(256,256))\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "    result=model(image)\n",
    "    output=result.pandas().xyxy[0]\n",
    "    return output #returns the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Riddhick/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-2-22 Python-3.9.5 torch-2.2.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "output_df=detect_objects(imagePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         xmin       ymin        xmax        ymax  confidence  class    name\n",
      "0  116.701477  45.346382  151.785828   73.473587    0.762813      0  person\n",
      "1  159.475128  23.756115  253.407791  246.825394    0.594860     17   horse\n",
      "2   24.415497  25.157923  128.289352  239.877441    0.394639     17   horse\n"
     ]
    }
   ],
   "source": [
    "print(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(output_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nodes(image):\n",
    "    output_df=detect_objects(image)\n",
    "    image_nodes=[]\n",
    "    for i in range(output_df.shape[0]):\n",
    "        #print(output_df.iloc[i]['name'])\n",
    "        data={\"object_id\":i,\n",
    "        \"start_point\":(round(output_df.iloc[i]['xmin']),round(output_df.iloc[i]['ymin'])),\n",
    "        \"ending_point\":(round(output_df.iloc[i]['xmax']),round(output_df.iloc[i]['ymax'])),\n",
    "        \"label\":output_df.iloc[i]['name']\n",
    "        }\n",
    "        image_nodes.append(data)\n",
    "    return image_nodes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nodeImages(imagePath,nodes):\n",
    "    image=cv2.imread(imagePath)\n",
    "    image=cv2.resize(image,(256,256))\n",
    "    #image = cv2.rectangle(image, (106,19), (188,133), (255, 0, 0) , 2) \n",
    "    #crop=image[19:133,106:188]\n",
    "    #cv2.imshow('image',crop)\n",
    "    #cv2.waitKey()\n",
    "    segment_array=[]\n",
    "    for i in range(len(nodes)):\n",
    "        start=nodes[i].get('start_point')\n",
    "        end=nodes[i].get('ending_point')\n",
    "        #print(end[1])\n",
    "        a,b,c,d=start[1],end[1],start[0],end[0]\n",
    "        crop=image[a:b,c:d]\n",
    "        segment_array.append(crop)\n",
    "    segment_array.append(image)    \n",
    "    return segment_array    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Riddhick/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-2-22 Python-3.9.5 torch-2.2.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'object_id': 0, 'start_point': (117, 45), 'ending_point': (152, 73), 'label': 'person'}, {'object_id': 1, 'start_point': (159, 24), 'ending_point': (253, 247), 'label': 'horse'}, {'object_id': 2, 'start_point': (24, 25), 'ending_point': (128, 240), 'label': 'horse'}]\n"
     ]
    }
   ],
   "source": [
    "nodes=extract_nodes(imagePath)\n",
    "print(nodes)\n",
    "#segment_array=generate_nodeImages(imagePath,nodes)\n",
    "#visualize_graph(segment_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_array=generate_nodeImages(imagePath,nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(segment_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,570,240\n",
      "Trainable params: 139,570,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#load the VGG19 model:\n",
    "model=VGG19()\n",
    "model=Model(inputs=model.inputs,outputs=model.layers[-2].output)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuresVGG(segment_array):\n",
    "    VGG_features=[]\n",
    "    for image in segment_array:\n",
    "        image=cv2.resize(image,(224,224))\n",
    "        image=img_to_array(image)\n",
    "        image=image.reshape((1,image.shape[0],image.shape[1],image.shape[2]))\n",
    "        image=preprocess_input(image)\n",
    "        feature=model.predict(image,verbose=0)\n",
    "        VGG_features.append(feature)\n",
    "    return VGG_features    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG=featuresVGG(segment_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4096)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     1.3155           0           0 ...      1.0103      1.7103           0]\n"
     ]
    }
   ],
   "source": [
    "print(VGG[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(VGG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.53010, 2.92149, 1.50596,  ..., 1.09558, 0.00000, 3.36610],\n",
      "        [0.00000, 0.00000, 0.00000,  ..., 0.00000, 1.14462, 2.79518],\n",
      "        [1.84861, 2.14890, 0.00000,  ..., 0.00000, 0.00000, 2.29957],\n",
      "        [7.25546, 0.00000, 2.02446,  ..., 0.00000, 0.00000, 0.00000]], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GCN using Relational Graph Convolution\n",
    "\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch.conv import RelGraphConv\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "g = dgl.DGLGraph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "num_nodes = len(VGG)\n",
    "g.add_nodes(num_nodes)\n",
    "\n",
    "# Create tensor for node features\n",
    "features = torch.tensor(VGG, dtype=torch.float32)\n",
    "\n",
    "# Add features to the graph\n",
    "g.ndata['features'] = features\n",
    "\n",
    "# Add edges to the graph with a complete graph\n",
    "num_edges = num_nodes * (num_nodes - 1)\n",
    "g.add_edges(torch.randint(num_nodes, (num_edges,)), torch.randint(num_nodes, (num_edges,)))\n",
    "\n",
    "# Initialize learnable edge weights\n",
    "g.edata['edge_weights'] = nn.Parameter(torch.rand(num_edges, requires_grad=True))\n",
    "\n",
    "# GCN model with RelGraphConv layer\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, out_feats, num_rels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.layer = RelGraphConv(in_feats, hidden_feats, num_rels, activation=F.relu)\n",
    "        #self.out_layer = nn.Linear(hidden_feats, out_feats)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        g = dgl.remove_self_loop(g)\n",
    "        # Perform relational graph convolution\n",
    "        h = self.layer(g, features, g.edata['edge_weights'])\n",
    "        \n",
    "        # fully connected layer\n",
    "        #output = self.out_layer(h)\n",
    "        return h\n",
    "\n",
    "# Reshape the features tensor\n",
    "features = features.squeeze(1)\n",
    "\n",
    "# Instantiate the GCN model with the number of relations and classes\n",
    "in_feats = features.shape[1]  # Number of input features\n",
    "hidden_feats = 256  # Number of hidden units\n",
    "num_classes = 5  # Number of classes for multiclass classification\n",
    "num_rels = 10  # Number of relations \n",
    "\n",
    "model = GCN(in_feats, hidden_feats, num_classes, num_rels) \n",
    "\n",
    "# Forward pass\n",
    "output = model(g, features)\n",
    "print(output)\n",
    "output.shape\n",
    "# Apply softmax to obtain class probabilities\n",
    "#probs = F.softmax(output, dim=1)\n",
    "\n",
    "#print(probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.00000, 1.38239, 0.00000,  ..., 0.76408, 0.00000, 0.18507],\n",
      "        [0.00000, 4.20069, 0.96631,  ..., 1.06541, 0.00000, 0.63017],\n",
      "        [0.00000, 4.15923, 1.60207,  ..., 0.37969, 0.00000, 0.66038],\n",
      "        [0.00000, 2.12240, 0.62677,  ..., 1.03850, 0.00000, 0.56967]], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GCN model using convetional Convulution Graph Network\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import GraphConv\n",
    "\n",
    "g = dgl.DGLGraph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "num_nodes = len(VGG)\n",
    "g.add_nodes(num_nodes)\n",
    "\n",
    "# Create tensor for node features\n",
    "features = torch.tensor(VGG, dtype=torch.float32)\n",
    "\n",
    "# Add features to the graph\n",
    "g.ndata['features'] = features\n",
    "\n",
    "# Add edges to the graph with learnable weights initialized randomly\n",
    "num_edges = num_nodes*num_nodes-1 \n",
    "g.add_edges(torch.randint(num_nodes, (num_edges,)), torch.randint(num_nodes, (num_edges,)))\n",
    "\n",
    "# Initialize learnable edge weights\n",
    "g.edata['edge_weights'] = nn.Parameter(torch.rand(num_edges, requires_grad=True))\n",
    "\n",
    "# Define a Graph Convolutional Network (GCN) model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv = GraphConv(in_feats, hidden_feats)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        # Perform graph convolution with learnable edge weights\n",
    "        h = self.conv(g, features)\n",
    "        h = F.relu(h)\n",
    "        return h\n",
    "\n",
    "# Reshape the features tensor\n",
    "features = features.squeeze(1)\n",
    "\n",
    "# Instantiate the GCN model\n",
    "in_feats = features.shape[1] # Number of input features\n",
    "hidden_feats = 256 # Number of hidden units\n",
    "model = GCN(in_feats, hidden_feats)\n",
    "\n",
    "# Forward pass\n",
    "output_gcn = model(g, features)\n",
    "\n",
    "\n",
    "print(output_gcn)\n",
    "output_gcn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import Tensor\n",
    "output=output_gcn.detach().numpy()\n",
    "#output=np.reshape(output_gcn,output_gcn.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 256)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b = output.flatten()\n",
    "#b=np.reshape(b,b.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          0     0.30215      0.6291 ...           0           0     0.72753]\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=output.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=output.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.50786           0     0.28418 ...      1.3954      5.5616           0]]\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b=np.reshape(b,b.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=1)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=1)\n",
    "pca.fit(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "s=StandardScaler()\n",
    "x=pca.transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    -1.2616]\n",
      " [     5.1594]\n",
      " [    0.57578]\n",
      " [    -1.2616]\n",
      " [    0.33297]\n",
      " [     0.2496]\n",
      " [    -1.0775]\n",
      " [    -1.2616]\n",
      " [     1.6534]\n",
      " [     0.2691]\n",
      " [    -0.7258]\n",
      " [    -1.1917]\n",
      " [   -0.95797]\n",
      " [    0.51899]\n",
      " [    0.18361]\n",
      " [   -0.26904]\n",
      " [    -1.2616]\n",
      " [    -1.0818]\n",
      " [     1.6243]\n",
      " [      2.012]\n",
      " [    -1.2616]\n",
      " [     1.1576]\n",
      " [     5.0555]\n",
      " [    -1.2616]\n",
      " [    -1.0644]\n",
      " [     1.3706]\n",
      " [    -1.2616]\n",
      " [    -1.0471]\n",
      " [   -0.66128]\n",
      " [     0.3533]\n",
      " [    -1.2616]\n",
      " [    -1.0162]\n",
      " [    -0.5418]\n",
      " [      4.545]\n",
      " [    -1.2616]\n",
      " [    -1.2616]\n",
      " [     4.3435]\n",
      " [    -1.2173]\n",
      " [     4.0678]\n",
      " [    -1.2616]\n",
      " [    -1.1928]\n",
      " [     1.2638]\n",
      " [     2.0019]\n",
      " [    -1.2616]\n",
      " [    -1.2616]\n",
      " [   -0.32235]\n",
      " [    -1.2616]\n",
      " [    -1.2616]\n",
      " [     3.1066]\n",
      " [    -1.2616]\n",
      " [     1.6483]\n",
      " [    -1.2616]\n",
      " [     1.6423]\n",
      " [   -0.89371]\n",
      " [   -0.66018]\n",
      " [    -1.2616]\n",
      " [   -0.72212]\n",
      " [    -1.2616]\n",
      " [    -1.1859]\n",
      " [    -1.2153]\n",
      " [  -0.020354]\n",
      " [    -1.2616]\n",
      " [    -1.2616]\n",
      " [   -0.75988]\n",
      " [    -1.2616]\n",
      " [    0.98595]\n",
      " [    -1.2616]\n",
      " [    0.76324]\n",
      " [    -1.2616]\n",
      " [    -1.1874]\n",
      " [   -0.78865]\n",
      " [   -0.27094]\n",
      " [   -0.99567]\n",
      " [    -1.1291]\n",
      " [    -1.2616]\n",
      " [   -0.58904]\n",
      " [     1.5584]\n",
      " [    -1.2616]\n",
      " [    -1.2616]\n",
      " [    -1.0943]\n",
      " [     2.1968]\n",
      " [    -1.2616]\n",
      " [   -0.78236]\n",
      " [   -0.36451]\n",
      " [     3.1034]\n",
      " [   -0.87994]\n",
      " [    -1.1939]\n",
      " [    -1.2616]\n",
      " [   -0.41572]\n",
      " [    -1.1952]\n",
      " [     2.9486]\n",
      " [    -0.8379]\n",
      " [   0.019336]\n",
      " [   -0.62655]\n",
      " [    -1.0988]\n",
      " [     4.7553]\n",
      " [    -1.2616]\n",
      " [     3.0816]\n",
      " [    -1.2616]\n",
      " [     1.4489]\n",
      " [     1.7488]\n",
      " [    0.33264]\n",
      " [  -0.017479]\n",
      " [    -1.2616]\n",
      " [    -1.2616]\n",
      " [    -1.2616]\n",
      " [    -1.2616]\n",
      " [    -1.2616]\n",
      " [    -1.2506]\n",
      " [    -1.0402]\n",
      " [    -1.2616]\n",
      " [    -1.2248]\n",
      " [      1.449]\n",
      " [    -1.2616]\n",
      " [     2.1605]\n",
      " [     3.1603]\n",
      " [    -1.2616]\n",
      " [     3.3541]\n",
      " [    -1.0163]\n",
      " [     1.4996]\n",
      " [       3.17]\n",
      " [     3.4488]\n",
      " [     1.1738]\n",
      " [    -1.2616]\n",
      " [   -0.58361]\n",
      " [    -1.2197]\n",
      " [     1.5531]\n",
      " [    -1.2616]\n",
      " [   -0.93207]\n",
      " [     2.4352]\n",
      " [    -1.2616]\n",
      " [   -0.60001]\n",
      " [     1.3944]\n",
      " [     0.8556]\n",
      " [   -0.36537]\n",
      " [      3.495]\n",
      " [   -0.66532]\n",
      " [   -0.11434]\n",
      " [    0.96854]\n",
      " [     1.5473]\n",
      " [      -0.38]\n",
      " [     0.0188]\n",
      " [     2.8147]\n",
      " [   -0.49793]\n",
      " [    -1.2616]\n",
      " [     0.2367]\n",
      " [    -1.2616]\n",
      " [     1.0947]\n",
      " [    -1.2616]\n",
      " [    -1.2616]\n",
      " [    -0.1558]\n",
      " [    -1.2616]\n",
      " [   -0.74873]\n",
      " [   -0.93745]\n",
      " [   0.016312]\n",
      " [   -0.81372]\n",
      " [   -0.24981]\n",
      " [    -1.2616]\n",
      " [    -1.2616]\n",
      " [   -0.51629]\n",
      " [     4.4796]\n",
      " [    -1.2616]\n",
      " [    -1.2616]\n",
      " [   0.042823]\n",
      " [    -1.2616]\n",
      " [    -1.1332]\n",
      " [   -0.92935]\n",
      " [        2.4]\n",
      " [    -1.2506]\n",
      " [    -1.2616]\n",
      " [     2.9781]\n",
      " [   -0.25541]\n",
      " [     1.4996]\n",
      " [     1.0026]\n",
      " [     3.9082]\n",
      " [    -1.2616]\n",
      " [    -1.0415]\n",
      " [    -1.1595]\n",
      " [     2.2267]\n",
      " [   -0.70052]\n",
      " [    -1.2616]\n",
      " [     1.4047]\n",
      " [    -1.1515]\n",
      " [    0.67927]\n",
      " [   -0.97561]\n",
      " [    -1.2229]\n",
      " [    -1.2264]\n",
      " [    -1.2616]\n",
      " [    0.90508]\n",
      " [    -1.1814]\n",
      " [    -1.2616]\n",
      " [     4.3728]\n",
      " [   -0.86554]\n",
      " [     -1.205]\n",
      " [    -1.2616]\n",
      " [    -1.2616]\n",
      " [   -0.87584]\n",
      " [    -1.2616]\n",
      " [    -1.2533]\n",
      " [    -1.2616]\n",
      " [     2.7665]\n",
      " [    -1.2083]\n",
      " [    -1.2616]\n",
      " [    -1.2616]\n",
      " [  -0.014323]\n",
      " [    -1.2616]\n",
      " [     5.8999]\n",
      " [    -1.2422]\n",
      " [    -1.2616]\n",
      " [    0.12753]\n",
      " [   -0.50401]\n",
      " [    0.21709]\n",
      " [     7.2898]\n",
      " [    -1.2248]\n",
      " [    -1.2616]\n",
      " [   -0.21927]\n",
      " [    -1.2616]\n",
      " [    0.93277]\n",
      " [     1.3323]\n",
      " [     1.6546]\n",
      " [    -1.2616]\n",
      " [     3.4436]\n",
      " [    -1.1241]\n",
      " [   -0.16464]\n",
      " [     1.2483]\n",
      " [    0.43033]\n",
      " [     4.4696]\n",
      " [   -0.76898]\n",
      " [   -0.60762]\n",
      " [   -0.86583]\n",
      " [     2.5889]\n",
      " [    -0.3315]\n",
      " [    -1.2616]\n",
      " [    -1.2616]\n",
      " [    0.83784]\n",
      " [    -1.2616]\n",
      " [   -0.94677]\n",
      " [     1.4929]\n",
      " [    0.33773]\n",
      " [   -0.89387]\n",
      " [      2.497]\n",
      " [     2.1378]\n",
      " [    -1.2616]\n",
      " [    -1.2088]\n",
      " [    0.97283]\n",
      " [     2.2933]\n",
      " [    -1.1782]\n",
      " [   -0.69979]\n",
      " [    -1.2616]\n",
      " [    0.55343]\n",
      " [    -1.2616]\n",
      " [    -1.2616]\n",
      " [    -1.2616]\n",
      " [    0.22817]\n",
      " [    -1.2616]\n",
      " [   -0.19661]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output=np.reshape(output,output.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.31777e-01, -2.08447e-02, -1.52904e-01, -1.32896e-01,  1.32941e-01,  1.34144e-01,  4.48199e-02,  1.76426e-01,  2.47702e-02, -1.40492e-01,  3.97684e-02, -1.07978e-01,  1.80426e-01, -1.14290e-02,  1.53168e-01,  7.91234e-02,  1.41230e-01, -2.26516e-01,  1.58732e-01, -1.00209e-01, -2.11133e-01, -1.34866e-01,\n",
      "          -1.56171e-01,  1.26189e-01,  2.00407e-01, -1.26752e-01, -1.42292e-02,  1.49252e-01, -3.14804e-02, -1.07960e-01,  1.55362e-01,  1.04021e-01,  2.98855e-02,  2.33520e-02,  1.03485e-01,  1.86764e-01,  7.54420e-02,  7.36205e-02,  9.82403e-02, -7.73489e-02,  1.24779e-02, -2.84458e-02,  2.23195e-03,  7.30309e-02,\n",
      "          -6.64143e-02, -4.31541e-02,  1.67844e-01,  3.06843e-02,  3.03529e-02,  9.53403e-02,  9.44292e-02,  5.36023e-02, -5.60734e-02,  1.01189e-01, -4.24863e-03,  1.78458e-02, -2.46704e-01,  2.94786e-02, -2.09040e-01,  1.81564e-01,  2.08055e-01,  2.09826e-02, -8.68400e-02,  1.16171e-01, -1.47190e-02, -9.32746e-02,\n",
      "           2.64793e-01, -6.98123e-02, -1.87539e-02,  1.62237e-01, -1.44043e-02,  3.84664e-02,  4.13440e-02, -1.88482e-01,  1.07704e-01, -2.58527e-01, -5.70126e-02, -1.13083e-01,  1.42117e-01, -3.90350e-02, -2.32129e-02,  4.13336e-02, -8.29003e-03, -2.53631e-02,  6.57040e-02, -7.37737e-02, -1.47772e-01,  6.27144e-02,\n",
      "          -6.44707e-02,  2.17060e-01,  1.13521e-01,  1.48518e-01, -1.47768e-02,  5.77483e-02,  3.99458e-02,  3.85124e-02, -1.97040e-01, -1.63135e-01, -2.85844e-02,  2.19048e-03, -1.58595e-02,  5.33082e-02,  5.59368e-02,  7.85198e-02, -2.01563e-02, -5.44689e-02, -4.97811e-02,  1.66222e-01,  8.69782e-02, -5.76898e-02,\n",
      "          -1.25602e-01,  5.32460e-02, -1.02759e-02, -2.72721e-02,  1.10571e-01,  2.13864e-01,  4.98731e-02,  8.43507e-02, -5.28598e-02, -1.08744e-01, -2.59817e-02,  1.07677e-02, -1.20065e-01,  1.07229e-01,  2.81728e-01,  4.54327e-02, -4.44932e-02, -1.63364e-01],\n",
      "         [ 1.62547e-01,  4.96756e-05, -2.38145e-01, -1.73986e-01,  1.68462e-01,  1.29745e-01, -1.19133e-02,  2.04802e-01,  1.65312e-02, -1.34938e-01,  7.19538e-02, -2.07782e-01,  1.63893e-01, -6.66191e-02,  1.52051e-01,  1.39107e-01,  1.69198e-01, -2.26540e-01,  2.66835e-01, -2.10464e-01, -2.61717e-01, -1.78826e-01,\n",
      "          -2.16012e-01,  2.19199e-01,  3.35088e-01, -1.19586e-01, -5.74532e-02,  2.58544e-01, -1.33654e-01, -1.69617e-01,  2.18607e-01, -9.73186e-03,  6.03353e-02, -1.83988e-02,  1.51411e-01,  1.29942e-01,  1.56723e-01,  1.05896e-01,  8.11177e-03, -4.26078e-02, -1.83224e-02, -6.29025e-02, -6.89367e-02,  1.26450e-01,\n",
      "          -8.04906e-02,  2.23940e-02,  7.55589e-02,  1.96591e-02,  9.56413e-03,  1.53192e-01,  1.13214e-01,  1.43680e-01, -7.95528e-02,  2.51215e-01, -1.56440e-02, -3.35427e-02, -2.83112e-01,  2.54157e-02, -2.91217e-01,  2.02798e-01,  2.82648e-01,  7.30168e-02,  1.59516e-02,  1.28711e-01, -1.29815e-02, -1.89411e-01,\n",
      "           4.80283e-01, -1.86430e-01, -6.05195e-02,  1.58259e-01, -2.11489e-02,  7.50748e-02,  2.23719e-02, -1.19246e-01,  1.62453e-01, -3.22607e-01, -8.36560e-02, -4.43293e-02,  1.54944e-01, -2.63742e-02,  4.90998e-03,  6.73901e-02,  7.79244e-02,  5.33668e-02, -1.17922e-03, -4.37398e-02, -2.38902e-01,  2.94040e-02,\n",
      "          -4.18702e-02,  2.40989e-01,  1.61220e-01,  3.18596e-01, -2.34955e-02,  2.21629e-02,  5.87163e-02, -1.04860e-01, -2.93793e-01, -2.81769e-01, -1.12804e-01,  1.03720e-02, -2.28620e-02, -1.22257e-02,  1.97464e-02,  2.79840e-02, -6.64046e-02, -1.06422e-02, -5.68628e-02,  2.85806e-01,  1.15660e-01,  3.17423e-02,\n",
      "          -3.03373e-01,  7.09269e-02, -6.67112e-02, -2.04531e-02,  1.05149e-01,  3.38953e-01,  5.24963e-02,  6.48213e-02, -1.06853e-01, -5.86770e-02, -7.99850e-02, -2.24454e-02, -3.25407e-01,  5.45740e-02,  4.00949e-01,  6.24791e-02, -3.58443e-02, -2.08382e-01],\n",
      "         [ 1.93011e-01,  2.79597e-02, -2.48050e-01, -1.72806e-01,  1.73282e-01,  1.25661e-01, -2.60050e-02,  1.83923e-01, -2.05134e-03, -1.30522e-01,  9.45838e-02, -2.41877e-01,  1.59186e-01, -9.56561e-02,  1.41943e-01,  1.55441e-01,  1.93843e-01, -2.04456e-01,  3.29888e-01, -2.58771e-01, -2.88451e-01, -2.12418e-01,\n",
      "          -2.50204e-01,  2.48248e-01,  3.89655e-01, -1.23199e-01, -8.61114e-02,  3.00899e-01, -1.93914e-01, -1.86355e-01,  2.55037e-01, -6.79803e-02,  8.00163e-02, -3.47718e-02,  1.78747e-01,  1.34766e-01,  2.03611e-01,  1.35352e-01, -1.82179e-02, -1.88614e-02, -4.29458e-02, -8.35818e-02, -1.05554e-01,  1.40068e-01,\n",
      "          -9.28935e-02,  3.35375e-02,  4.99161e-02,  7.64184e-03, -1.89392e-03,  1.99306e-01,  1.24715e-01,  1.67917e-01, -6.54393e-02,  3.24724e-01, -3.94445e-02, -5.88883e-02, -3.20631e-01,  2.03759e-02, -3.36611e-01,  2.40206e-01,  3.17232e-01,  9.39928e-02,  5.09111e-02,  1.20676e-01, -3.17251e-03, -2.40854e-01,\n",
      "           5.76506e-01, -2.48120e-01, -8.35852e-02,  1.82722e-01, -3.11606e-02,  8.72790e-02,  1.14218e-02, -1.01452e-01,  1.80431e-01, -3.57595e-01, -9.69894e-02,  2.67971e-02,  1.79097e-01, -2.41451e-02,  8.23045e-03,  8.43453e-02,  9.28733e-02,  8.65451e-02, -3.26549e-02, -2.98991e-02, -2.83983e-01,  1.98644e-02,\n",
      "          -2.63825e-02,  2.46699e-01,  1.84462e-01,  4.26781e-01, -4.13876e-02,  3.72109e-03,  6.31575e-02, -1.85248e-01, -3.46721e-01, -3.40519e-01, -1.39674e-01,  1.54012e-02, -2.23573e-02, -4.52791e-02,  2.56660e-02,  4.37384e-03, -7.99932e-02,  2.44528e-03, -4.78537e-02,  3.04779e-01,  1.33451e-01,  6.42861e-02,\n",
      "          -3.49646e-01,  6.17364e-02, -8.33985e-02, -1.89976e-02,  1.09091e-01,  3.93436e-01,  4.73039e-02,  5.56626e-02, -1.21111e-01, -3.94666e-02, -9.73653e-02, -4.27172e-02, -4.22366e-01,  4.72358e-02,  4.43397e-01,  7.02231e-02, -3.26006e-02, -2.19628e-01]]], grad_fn=<TransposeBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshape the output of GCN for LSTM\n",
    "batch_size = 1  #processing one graph at a time\n",
    "num_nodes = g.number_of_nodes()\n",
    "output_gcn = output_gcn.view(batch_size, num_nodes, hidden_feats)\n",
    "\n",
    "# LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = self.lstm(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "lstm_model = LSTM(hidden_feats, 128)  # 128 hidden units \n",
    "\n",
    "# Forward pass \n",
    "output_lstm = lstm_model(output_gcn)\n",
    "\n",
    "\n",
    "print(output_lstm)\n",
    "output_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
